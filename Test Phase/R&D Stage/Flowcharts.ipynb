{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMPSx2nP2oD5F6+lfpHF0xI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Bk9LCqjFoYCO","executionInfo":{"status":"ok","timestamp":1738767732146,"user_tz":-330,"elapsed":691,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"3e6bdd26-83c1-4f48-cbdc-91ad4a06638e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'gan_project_pipeline.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='GAN Project Pipeline', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges for each phase\n","dot.node('A', 'Phase 1: Research & Setup', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('B', 'Phase 2: Data Preparation', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('C', 'Phase 3: Model Development', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('D', 'Phase 4: Backend Development', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('E', 'Phase 5: Frontend-Backend Integration', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('F', 'Phase 6: Testing & Optimization', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('G', 'Phase 7: Deployment & Monitoring', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges to show the flow\n","dot.edge('A', 'B', label='1 week')\n","dot.edge('B', 'C', label='2 weeks')\n","dot.edge('C', 'D', label='4 weeks')\n","dot.edge('D', 'E', label='2 weeks')\n","dot.edge('E', 'F', label='1 week')\n","dot.edge('F', 'G', label='1 week')\n","\n","# Add sub-nodes for each phase\n","with dot.subgraph(name='cluster_1') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 1: Research & Setup')\n","    c.node('A1', 'Study GAN Variants')\n","    c.node('A2', 'Tools & Frameworks')\n","    c.node('A3', 'Infrastructure Setup')\n","    c.edges([('A1', 'A2'), ('A2', 'A3')])\n","\n","with dot.subgraph(name='cluster_2') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 2: Data Preparation')\n","    c.node('B1', 'Datasets: MNIST, CelebA, FFHQ, etc.')\n","    c.node('B2', 'Preprocessing: Normalization, Augmentation')\n","    c.edges([('B1', 'B2')])\n","\n","with dot.subgraph(name='cluster_3') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 3: Model Development')\n","    c.node('C1', 'Unconditional GAN (DCGAN)')\n","    c.node('C2', 'Conditional GAN (cGAN)')\n","    c.node('C3', 'BigGAN')\n","    c.node('C4', 'StyleGAN3')\n","    c.edges([('C1', 'C2'), ('C2', 'C3'), ('C3', 'C4')])\n","\n","with dot.subgraph(name='cluster_4') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 4: Backend Development')\n","    c.node('D1', 'API Endpoints: /upload-image, /generate-image')\n","    c.node('D2', 'NLP Integration: Emotion Analysis')\n","    c.node('D3', 'Model Serving: ONNX/TensorRT')\n","    c.edges([('D1', 'D2'), ('D2', 'D3')])\n","\n","with dot.subgraph(name='cluster_5') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 5: Frontend-Backend Integration')\n","    c.node('E1', 'Real-Time Communication: WebSocket')\n","    c.node('E2', 'Chat Interface: Upload/Webcam')\n","    c.node('E3', 'LLM Chat: GPT-3.5/4 Integration')\n","    c.edges([('E1', 'E2'), ('E2', 'E3')])\n","\n","with dot.subgraph(name='cluster_6') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 6: Testing & Optimization')\n","    c.node('F1', 'Unit Testing: Model Outputs, APIs')\n","    c.node('F2', 'Performance Optimization')\n","    c.node('F3', 'User Testing')\n","    c.edges([('F1', 'F2'), ('F2', 'F3')])\n","\n","with dot.subgraph(name='cluster_7') as c:\n","    c.attr(color='lightgrey', style='filled', label='Phase 7: Deployment & Monitoring')\n","    c.node('G1', 'Cloud Deployment: AWS/Google Cloud')\n","    c.node('G2', 'Monitoring: Prometheus/Grafana')\n","    c.edges([('G1', 'G2')])\n","\n","# Render the flowchart\n","dot.render('gan_project_pipeline', view=True)"]},{"cell_type":"code","source":["#Phase 1: Research & Setup\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 1: Research & Setup', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('A1', 'Study GAN Variants', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('A2', 'Tools & Frameworks', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('A3', 'Infrastructure Setup', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('A1', 'A2', label='Understand GANs')\n","dot.edge('A2', 'A3', label='Set up tools and infrastructure')\n","\n","# Render the flowchart\n","dot.render('phase_1_research_setup', view=True)"],"metadata":{"id":"-rQbLdMKPIFt","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1738777939877,"user_tz":-330,"elapsed":1532,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"f3bccb60-950a-489b-d018-59e6bc67f0b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_1_research_setup.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["#Phase 2: Data Preparation\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 2: Data Preparation', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('B1', 'Datasets: MNIST, CelebA, FFHQ', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('B2', 'Preprocessing: Normalization', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('B3', 'Preprocessing: Augmentation', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('B1', 'B2', label='Load datasets')\n","dot.edge('B2', 'B3', label='Apply preprocessing')\n","\n","# Render the flowchart\n","dot.render('phase_2_data_preparation', view=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gjnApTzmPqqw","executionInfo":{"status":"ok","timestamp":1738778012960,"user_tz":-330,"elapsed":629,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"741dad1c-586f-4124-8dc6-918552604d02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_2_data_preparation.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["#Phase 3: Model Development\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 3: Model Development', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('C1', 'Unconditional GAN (DCGAN)', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('C2', 'Conditional GAN (cGAN)', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('C3', 'BigGAN', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('C4', 'StyleGAN3', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('C1', 'C2', label='Add conditioning')\n","dot.edge('C2', 'C3', label='Scale up architecture')\n","dot.edge('C3', 'C4', label='Style-based generation')\n","\n","# Render the flowchart\n","dot.render('phase_3_model_development', view=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"yHJduV39P9hM","executionInfo":{"status":"ok","timestamp":1738778083468,"user_tz":-330,"elapsed":371,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"e89ed996-8026-440a-9d1f-7902b0753c81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_3_model_development.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#Phase 4: Backend Development\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 4: Backend Development', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('D1', 'API Endpoints: /upload-image, /generate-image', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('D2', 'NLP Integration: Emotion Analysis', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('D3', 'Model Serving: ONNX/TensorRT', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('D1', 'D2', label='Integrate NLP for prompts')\n","dot.edge('D2', 'D3', label='Optimize model serving')\n","\n","# Render the flowchart\n","dot.render('phase_4_backend_development', view=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8AE-XvJPQIJ9","executionInfo":{"status":"ok","timestamp":1738778136883,"user_tz":-330,"elapsed":416,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"52bc3504-7ba3-48de-c5db-adf52769bdf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_4_backend_development.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#Phase 5: Frontend-Backend Integration\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 5: Frontend-Backend Integration', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('E1', 'Real-Time Communication: WebSocket', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('E2', 'Chat Interface: Upload/Webcam', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('E3', 'LLM Chat: GPT-3.5/4 Integration', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('E1', 'E2', label='Enable live image upload')\n","dot.edge('E2', 'E3', label='Add conversational AI')\n","\n","# Render the flowchart\n","dot.render('phase_5_frontend_backend_integration', view=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1B5P5rWUQXcm","executionInfo":{"status":"ok","timestamp":1738778199638,"user_tz":-330,"elapsed":355,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"5e501f4b-3d37-41ff-ae52-57b9b047dfd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_5_frontend_backend_integration.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#Phase 6: Testing & Optimization\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 6: Testing & Optimization', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('F1', 'Unit Testing: Model Outputs, APIs', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('F2', 'Performance Optimization', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('F3', 'User Testing', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('F1', 'F2', label='Optimize inference time')\n","dot.edge('F2', 'F3', label='Collect user feedback')\n","\n","# Render the flowchart\n","dot.render('phase_6_testing_optimization', view=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"omTZGmfhQowc","executionInfo":{"status":"ok","timestamp":1738778261851,"user_tz":-330,"elapsed":544,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"3faf4eb5-985e-48ac-dff4-680e4a62cd20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_6_testing_optimization.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["pip install graphviz\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ak5YgftUbTxh","executionInfo":{"status":"ok","timestamp":1739116598657,"user_tz":-330,"elapsed":2820,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"27c9df99-63e4-427d-9cd9-b07fabf1078a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.20.3)\n"]}]},{"cell_type":"code","source":["#Phase 7: Deployment & Monitoring\n","from graphviz import Digraph\n","\n","# Create a Digraph object\n","dot = Digraph(comment='Phase 7: Deployment & Monitoring', format='png')\n","dot.attr(bgcolor='white')  # Set background to white\n","\n","# Add nodes and edges\n","dot.node('G1', 'Cloud Deployment: AWS/Google Cloud', shape='box', style='filled', fillcolor='lightblue')\n","dot.node('G2', 'Monitoring: Prometheus/Grafana', shape='box', style='filled', fillcolor='lightblue')\n","\n","# Add edges\n","dot.edge('G1', 'G2', label='Set up monitoring tools')\n","\n","# Render the flowchart\n","dot.render('phase_7_deployment_monitoring', view=True)"],"metadata":{"id":"rkKa40ILQ7ci","executionInfo":{"status":"ok","timestamp":1738778337096,"user_tz":-330,"elapsed":382,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}},"outputId":"9f9a5464-4797-4246-b557-383c86931f21","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phase_7_deployment_monitoring.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from graphviz import Digraph\n","\n","def create_flowchart():\n","    # Create a Digraph with high resolution (300 dpi)\n","    dot = Digraph('GAN_Project_Flowchart', filename='gan_project_flowchart', format='png')\n","    dot.attr(rankdir='LR', dpi='300')  # Left-to-right layout with high DPI\n","\n","    # Global node style settings\n","    dot.attr('node', shape='rectangle', style='filled,rounded', fontname='Helvetica', fontsize='10', margin='0.2,0.1')\n","\n","    # Define main nodes with different fill colors\n","    dot.node('A', 'Research & Setup', fillcolor='lightblue')\n","    dot.node('B', 'Data Preparation', fillcolor='lightgreen')\n","    dot.node('C', 'Model Development', fillcolor='yellow')\n","    dot.node('D', 'Backend Development\\n(API & Deployment)', fillcolor='orange')\n","    dot.node('E', 'Frontend Integration\\n(UI/UX)', fillcolor='pink')\n","    dot.node('F', 'NLP & LLM Integration\\n(Text-to-Image)', fillcolor='violet')\n","    dot.node('G', 'Testing & Optimization', fillcolor='lightgrey')\n","    dot.node('H', 'Deployment & Monitoring', fillcolor='lightcoral')\n","\n","    # Define subnodes for Model Development\n","    dot.node('C1', 'DCGAN', fillcolor='wheat')\n","    dot.node('C2', 'CGAN', fillcolor='wheat')\n","    dot.node('C3', 'BigGAN', fillcolor='wheat')\n","    dot.node('C4', 'StyleGAN3', fillcolor='wheat')\n","\n","    # Create edges for the overall project flow\n","    dot.edge('A', 'B')\n","    dot.edge('B', 'C')\n","    dot.edge('C', 'D')\n","    dot.edge('D', 'E')\n","    dot.edge('E', 'F')\n","    dot.edge('F', 'G')\n","    dot.edge('G', 'H')\n","\n","    # Create edges for the subnodes of Model Development (branching from C)\n","    dot.edge('C', 'C1')\n","    dot.edge('C', 'C2')\n","    dot.edge('C', 'C3')\n","    dot.edge('C', 'C4')\n","\n","    # Optionally, to keep the subnodes visually linked, you can group them together.\n","    # For instance, you might want to have them arranged in a row:\n","    with dot.subgraph(name='cluster_models') as c:\n","        c.attr(style='invis')\n","        c.node('C1')\n","        c.node('C2')\n","        c.node('C3')\n","        c.node('C4')\n","        c.attr(rank='same')\n","\n","    # Render and view the graph\n","    dot.render(view=True)\n","\n","if __name__ == '__main__':\n","    create_flowchart()\n"],"metadata":{"id":"0ZTJLCq-a6OE","executionInfo":{"status":"ok","timestamp":1739116621112,"user_tz":-330,"elapsed":297,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from graphviz import Digraph\n","\n","def create_gan_methodology_flowchart():\n","    # Create a directed graph with top-to-bottom layout and high resolution\n","    dot = Digraph('GAN_Methodology', filename='gan_methodology_flowchart', format='png')\n","    dot.attr(rankdir='TB', dpi='300')  # TB: Top-to-Bottom layout\n","\n","    # Set global node style\n","    dot.attr('node', shape='rectangle', style='filled,rounded', fontname='Helvetica', fontsize='10', margin='0.2,0.1')\n","\n","    # Define nodes representing each step in the GAN methodology\n","    dot.node('A', 'Start: Initialize GAN', fillcolor='lightblue')\n","    dot.node('B', 'Input Noise Vector (z)', fillcolor='lightgreen')\n","    dot.node('C', 'Generator:\\nProduce Fake Image', fillcolor='yellow')\n","    dot.node('D', 'Real Image:\\nFetch from Dataset', fillcolor='lightcoral')\n","    dot.node('E', 'Discriminator:\\nEvaluate Real & Fake Images', fillcolor='orange')\n","    dot.node('F', 'Compute Losses\\n(for Generator & Discriminator)', fillcolor='violet')\n","    dot.node('G', 'Backpropagation\\nAdjust Weights', fillcolor='lightgrey')\n","    dot.node('H', 'Update Model Weights\\n(Generator & Discriminator)', fillcolor='pink')\n","    dot.node('I', 'Next Training Iteration', fillcolor='wheat')\n","    dot.node('J', 'Convergence/Stop Training', fillcolor='lightblue')\n","\n","    # Connect nodes with edges to define the flow\n","    dot.edge('A', 'B', label='Initialize')\n","    dot.edge('B', 'C', label='Noise → Fake Image')\n","    dot.edge('C', 'E', label='Fake Image')\n","    dot.edge('D', 'E', label='Real Image')\n","    dot.edge('E', 'F', label='Evaluation')\n","    dot.edge('F', 'G', label='Loss Computation')\n","    dot.edge('G', 'H', label='Gradient Descent')\n","    dot.edge('H', 'I', label='Update Weights')\n","    dot.edge('I', 'B', label='Repeat Iteration')\n","    dot.edge('I', 'J', label='If Converged')\n","\n","    # Render the flowchart to a PNG image and open it\n","    dot.render(view=True)\n","\n","if __name__ == '__main__':\n","    create_gan_methodology_flowchart()\n"],"metadata":{"id":"5v54PbYycwfn","executionInfo":{"status":"ok","timestamp":1739116975631,"user_tz":-330,"elapsed":276,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from graphviz import Digraph\n","\n","def create_project_flowchart():\n","    # Create a directed graph with a top-to-bottom layout and high resolution (300 dpi)\n","    dot = Digraph('Project_Flowchart', filename='project_flowchart', format='png')\n","    dot.attr(rankdir='TB', dpi='300')\n","    dot.attr('node', shape='rectangle', style='filled,rounded', fontname='Helvetica', fontsize='10', margin='0.2,0.1')\n","\n","    # ----------------------\n","    # Cluster: Backend Development\n","    # ----------------------\n","    with dot.subgraph(name='cluster_backend') as backend:\n","        backend.attr(label='Backend Development\\n(API & Deployment)', style='filled', color='lightblue', fillcolor='lightblue')\n","        backend.node('B1', 'Flask-based Backend\\nServe GAN Models')\n","        backend.node('B2', 'API Endpoints\\nHandle user requests,\\nreceive input images, return outputs')\n","        backend.node('B3', 'Database Integration\\nUser Authentication & Session Management')\n","        backend.node('B4', 'Performance Optimization\\nFaster response times & Scalability')\n","        backend.edge('B1', 'B2')\n","        backend.edge('B2', 'B3')\n","        backend.edge('B3', 'B4')\n","\n","    # ----------------------\n","    # Cluster: Frontend Integration\n","    # ----------------------\n","    with dot.subgraph(name='cluster_frontend') as frontend:\n","        frontend.attr(label='Frontend Integration (UI/UX)', style='filled', color='lightgreen', fillcolor='lightgreen')\n","        frontend.node('F1', 'React.js Frontend\\nInteractive & User-Friendly')\n","        frontend.node('F2', 'Login/Signup Page\\nName & Roll Number Authentication')\n","        frontend.node('F3', 'Prompt Page\\nSelect face image & emotion transformation')\n","        frontend.node('F4', 'Real-time Updates\\nDisplay image processing results')\n","        frontend.edge('F1', 'F2')\n","        frontend.edge('F2', 'F3')\n","        frontend.edge('F3', 'F4')\n","\n","    # ----------------------\n","    # Cluster: NLP & LLM Integration\n","    # ----------------------\n","    with dot.subgraph(name='cluster_nlp') as nlp:\n","        nlp.attr(label='NLP & LLM Integration\\n(Text-to-Image)', style='filled', color='yellow', fillcolor='yellow')\n","        nlp.node('N1', 'NLP Models\\nProcess text-based emotion descriptions')\n","        nlp.node('N2', 'LLM Integration\\nGuide emotion selection\\nvia text prompts')\n","        nlp.node('N3', 'AI-powered Suggestions\\nBased on past selections')\n","        nlp.edge('N1', 'N2')\n","        nlp.edge('N2', 'N3')\n","\n","    # ----------------------\n","    # Cluster: Testing & Optimization\n","    # ----------------------\n","    with dot.subgraph(name='cluster_testing') as testing:\n","        testing.attr(label='Testing & Optimization', style='filled', color='orange', fillcolor='orange')\n","        testing.node('T1', 'Unit Testing\\n(Frontend, Backend, Model Inference)')\n","\n","    # ----------------------\n","    # Cluster: Deployment & Monitoring\n","    # ----------------------\n","    with dot.subgraph(name='cluster_deployment') as deployment:\n","        deployment.attr(label='Deployment & Monitoring', style='filled', color='violet', fillcolor='violet')\n","        deployment.node('D1', 'Deploy Flask API\\n(AWS/Google Cloud/Heroku)')\n","        deployment.node('D2', 'Host React Frontend\\n(Vercel/Netlify)')\n","        deployment.node('D3', 'Logging & Monitoring\\nTrack user activity, detect issues')\n","        deployment.node('D4', 'Automated Updates & Model Retraining\\nContinuous improvements')\n","        deployment.edge('D1', 'D2')\n","        deployment.edge('D2', 'D3')\n","        deployment.edge('D3', 'D4')\n","\n","    # ----------------------\n","    # Connect Clusters to Reflect Overall Workflow\n","    # ----------------------\n","    # The workflow flows from backend development to frontend integration,\n","    # then integrates NLP/LLM, followed by testing and finally deployment.\n","    dot.edge('B4', 'F1', label='Integrate')\n","    dot.edge('F4', 'N1', label='Text-to-Image Integration')\n","    dot.edge('N3', 'T1', label='Validate & Test')\n","    dot.edge('T1', 'D1', label='Deploy')\n","\n","    # Render and view the flowchart as a PNG image\n","    dot.render(view=True)\n","\n","if __name__ == '__main__':\n","    create_project_flowchart()\n"],"metadata":{"id":"sZCUBlPUpCNF","executionInfo":{"status":"ok","timestamp":1739120285026,"user_tz":-330,"elapsed":322,"user":{"displayName":"Deep Habiswashi","userId":"14306398219012041066"}}},"execution_count":7,"outputs":[]}]}